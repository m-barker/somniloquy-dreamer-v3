defaults:
  logdir: null
  traindir: null
  evaldir: null
  offline_traindir: ""
  offline_evaldir: ""
  seed: 420
  deterministic_run: False
  steps: 1e6
  parallel: False
  eval_every: 1e4
  eval_episode_num: 10
  log_every: 1e4
  reset_every: 0
  device: "cuda:0"
  compile: True
  precision: 32
  debug: False
  video_pred_log: True
  checkpoint: null
  n_eval_samples: 10
  eval_trajectory_length: 16
  eval_n_consecutive_trajectories: 2
  token_sampling_method: "nucleus"
  ignore_list: []
  no_convert_list: []
  narrator: { narration_key: [] }

  # Environment
  task: "dmc_walker_walk"
  size: [64, 64]
  envs: 1
  action_repeat: 2
  time_limit: 1000
  grayscale: False
  prefill: 2500
  reward_EMA: True

  # Model
  enable_language: false
  enable_language_to_latent: false
  enable_language_to_action: false
  action_prediction: false
  dyn_hidden: 512
  dyn_deter: 512
  dyn_stoch: 32
  dyn_discrete: 32
  dyn_rec_depth: 1
  dyn_mean_act: "none"
  dyn_std_act: "sigmoid2"
  dyn_min_std: 0.1
  grad_heads: ["decoder", "reward", "cont"]
  units: 512
  act: "SiLU"
  norm: True
  encoder:
    {
      mlp_keys: "$^",
      cnn_keys: "image",
      act: "SiLU",
      norm: True,
      cnn_depth: 32,
      kernel_size: 4,
      minres: 4,
      mlp_layers: 5,
      mlp_units: 1024,
      symlog_inputs: True,
    }
  decoder:
    {
      mlp_keys: "$^",
      cnn_keys: "image",
      act: "SiLU",
      norm: True,
      cnn_depth: 32,
      kernel_size: 4,
      minres: 4,
      mlp_layers: 5,
      mlp_units: 1024,
      cnn_sigmoid: False,
      image_dist: mse,
      vector_dist: symlog_mse,
      outscale: 1.0,
    }
  actor:
    {
      layers: 2,
      dist: "normal",
      entropy: 3e-4,
      unimix_ratio: 0.01,
      std: "learned",
      min_std: 0.1,
      max_std: 1.0,
      temp: 0.1,
      lr: 3e-5,
      eps: 1e-5,
      grad_clip: 100.0,
      outscale: 1.0,
    }
  critic:
    {
      layers: 2,
      dist: "symlog_disc",
      slow_target: True,
      slow_target_update: 1,
      slow_target_fraction: 0.02,
      lr: 3e-5,
      eps: 1e-5,
      grad_clip: 100.0,
      outscale: 0.0,
    }
  reward_head:
    { layers: 2, dist: "symlog_disc", loss_scale: 1.0, outscale: 0.0 }
  action_prediction_head:
    { layers: 2, dist: "onehot", loss_scale: 1.0, outscale: 0.0 }
  cont_head: { layers: 2, loss_scale: 1.0, outscale: 1.0 }
  dyn_scale: 0.5
  rep_scale: 0.1
  kl_free: 1.0
  weight_decay: 0.0
  unimix_ratio: 0.01
  initial: "learned"

  # Training
  batch_size: 16
  batch_length: 64
  # The ratio of model update steps: environment steps
  train_ratio: 512
  pretrain: 100
  model_lr: 1e-4
  opt_eps: 1e-8
  grad_clip: 1000
  dataset_size: 1000000
  opt: "adam"

  # Behavior.
  discount: 0.997
  discount_lambda: 0.95
  imag_horizon: 15
  imag_gradient: "dynamics"
  imag_gradient_mix: 0.0
  eval_state_mean: False

  # Exploration
  expl_behavior: "greedy"
  expl_until: 0
  expl_extr_scale: 0.0
  expl_intr_scale: 1.0
  disag_target: "stoch"
  disag_log: True
  disag_models: 10
  disag_offset: 1
  disag_layers: 4
  disag_units: 400
  disag_action_cond: False

dmc_proprio:
  steps: 5e5
  action_repeat: 2
  envs: 4
  train_ratio: 512
  video_pred_log: false
  encoder: { mlp_keys: ".*", cnn_keys: "$^" }
  decoder: { mlp_keys: ".*", cnn_keys: "$^" }

dmc_vision:
  steps: 1e6
  action_repeat: 2
  envs: 4
  train_ratio: 512
  video_pred_log: true
  encoder: { mlp_keys: "$^", cnn_keys: "image" }
  decoder: { mlp_keys: "$^", cnn_keys: "image" }

crafter:
  task: crafter_reward
  step: 1e6
  action_repeat: 1
  envs: 1
  eval_episode_num: 1
  eval_every: 500
  train_ratio: 512
  video_pred_log: true
  dyn_hidden: 1024
  dyn_deter: 4096
  units: 1024
  log_every: 500
  enable_language: true
  enc_max_length: 16
  dec_max_length: 150
  enable_language_to_action: true
  eval_strings:
    [
      "I will see tree, cow, and grass. I will harvest 1 wood. I will not craft anything. I will not eat anything and get more hungry. I will not drink anything and get more thirsty. I will not sleep and get more tired.",
    ]
  vocab_path: vocab/crafter.json
  narrator: { narration_key: ["semantic", "inventory", "achievements"] }
  no_convert_list: ["semantic", "inventory", "achievements"]
  encoder:
    {
      mlp_keys: "$^",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  decoder:
    {
      mlp_keys: "$^",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  actor: { layers: 5, dist: "onehot", std: "none" }
  value: { layers: 5 }
  reward_head: { layers: 5 }
  cont_head: { layers: 5 }
  imag_gradient: "reinforce"
  # checkpoint: "logdir/crafter-action-translation/latest.pt"

atari100k:
  steps: 4e5
  envs: 1
  action_repeat: 4
  train_ratio: 1024
  video_pred_log: true
  eval_episode_num: 100
  actor: { dist: "onehot", std: "none" }
  imag_gradient: "reinforce"
  stickey: False
  lives: unused
  noops: 30
  resize: opencv
  actions: needed
  time_limit: 108000

minecraft:
  task: minecraft_diamond
  step: 1e8
  parallel: True
  envs: 16
  # no eval
  eval_episode_num: 0
  eval_every: 1e4
  action_repeat: 1
  train_ratio: 16
  video_pred_log: true
  dyn_hidden: 1024
  dyn_deter: 4096
  units: 1024
  encoder:
    {
      mlp_keys: "inventory|inventory_max|equipped|health|hunger|breath|obs_reward",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  decoder:
    {
      mlp_keys: "inventory|inventory_max|equipped|health|hunger|breath",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  actor: { layers: 5, dist: "onehot", std: "none" }
  value: { layers: 5 }
  reward_head: { layers: 5 }
  cont_head: { layers: 5 }
  imag_gradient: "reinforce"
  break_speed: 100.0
  time_limit: 36000

memorymaze:
  steps: 1e8
  action_repeat: 2
  actor: { dist: "onehot", std: "none" }
  imag_gradient: "reinforce"
  task: "memorymaze_9x9"

minigrid:
  seed: 42
  steps: 1e6
  envs: 1
  action_repeat: 1
  eval_episode_num: 1
  eval_every: 1000
  log_every: 500
  actor: { dist: "onehot", std: "none" }
  # encoder: { mlp_keys: "flattened_occupancy_grid", cnn_keys: "image" }
  # decoder: { mlp_keys: "flattened_occupancy_grid", cnn_keys: "image" }
  narrator: { narration_key: ["occupancy_grid"] }
  imag_gradient: "reinforce"
  actions: needed
  enable_language: true
  enable_language_to_action: false
  action_prediction: false
  vocab_path: vocab/minigrid_four_squares.json
  dec_max_length: 30
  enc_max_length: 16
  video_pred_log: true
  eval_strings:
    [
      "the agent did not move",
      "the agent moved towards the green square which is the goal",
      "the agent reached the goal",
      "the agent moved in a circle",
      "the agent moved towards the purple square which is not the goal.",
    ]
  # task: "minigrid_teleport_complex"
  task: "minigrid_four_squares"
  time_limit: 1024
  # dyn_stoch: 16
  # dyn_discrete: 16
  # checkpoint: "/home/mattbarker/dev/somniloquy-dreamer-v3/logdir/minigrid-stochastic-occupancy-grid-longer-train/dreamer-agent-step-19500.pt"
  # checkpoint: "/home/mattbarker/dev/somniloquy-dreamer-v3/logdir/minigrid-stochastic-language-to-latent-test/dreamer-agent-step-57000.pt"
  # checkpoint: "/home/mattbarker/dev/somniloquy-dreamer-v3/logdir/minigrid-four-squares/dreamer-agent-step-42256.pt"
  # checkpoint: "/home/mattbarker/dev/somniloquy-dreamer-v3/logdir/minigrid-four-square-perplexity-test/latest.pt"

minedojo:
  steps: 1e8
  envs: 1
  eval_episode_num: 0
  eval_every: 1e4
  action_repeat: 1
  train_ratio: 16
  log_every: 1000
  resize: opencv
  actions: needed
  video_pred_log: true
  task: "minedojo_hunt_cow"
  minedojo_task_id: "hunt_cow"
  time_limit: 1000
  enable_language: true
  narrator: { narration_key: "image" }
  world_seed: 128
  vocab_path: vocab/mindojo_hunt_cow.json
  prompt_path: captions/minedojo.json
  mineclip_ckpt_path: attn.pth
  dec_max_length: 50
  enc_max_length: 16
  dyn_hidden: 1024
  dyn_deter: 4096
  units: 1024
  encoder:
    {
      mlp_keys: "compass|position|voxel_meta",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  decoder:
    {
      mlp_keys: "compass|position",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  actor: { layers: 5, dist: "onehot", std: "none" }
  value: { layers: 5 }
  reward_head: { layers: 5 }
  cont_head: { layers: 5 }
  imag_gradient: "reinforce"
  # checkpoint: "/data/Matt/dev/somniloquy-dreamer-v3/logdir/minedojo-hunt-cow/dreamer-agent-step-412500.pt"

panda_push:
  steps: 1e8
  action_repeat: 1
  envs: 16
  train_ratio: 64
  video_pred_log: true
  eval_episode_num: 0
  eval_every: 10000
  enable_language: true
  time_limit: 36000
  log_every: 1000
  dyn_hidden: 1024
  dyn_deter: 4096
  units: 1024
  task: "panda_push_colour"
  vocab_path: vocab/panda_push_colour.json
  narrator: { narration_key: "privileged_obs" }
  encoder:
    {
      mlp_keys: "$^",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  decoder:
    {
      mlp_keys: "$^",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  dec_max_length: 100
  enc_max_length: 16
  actor: { layers: 5 }
  value: { layers: 5 }
  reward_head: { layers: 5 }
  cont_head: { layers: 5 }
  # checkpoint: "/home/mattbarker/dev/somniloquy-dreamer-v3/logdir/panda-push-colour-with-lang/dreamer-agent-step-102500.pt"

debug:
  debug: True
  pretrain: 1
  prefill: 1
  batch_size: 10
  batch_length: 20
