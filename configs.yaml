defaults:
  logdir: null
  traindir: null
  evaldir: null
  offline_traindir: ""
  offline_evaldir: ""
  seed: 0
  log_translation_eval: True
  deterministic_run: False
  steps: 1e6
  parallel: False
  eval_every: 1e4
  eval_episode_num: 10
  log_every: 1e4
  reset_every: 0
  device: "cuda:0"
  compile: True
  precision: 32
  debug: False
  video_pred_log: True
  checkpoint: null
  n_eval_samples: 10
  eval_trajectory_length: 15
  eval_n_consecutive_trajectories: 10
  token_sampling_method: "nucleus"
  use_stopwords: False
  ignore_list: []
  no_convert_list: []
  narrator: { narration_key: [] }
  conditional_actions: False
  conditional_policy_attempts: 15
  conditional_epsilon: 0.1
  save_plots: True
  save_translations: True

  # Environment
  task: "dmc_walker_walk"
  size: [64, 64]
  envs: 1
  action_repeat: 2
  time_limit: 1000
  grayscale: False
  prefill: 2500
  reward_EMA: True

  # Model - DreamerV3 100M Version.
  enable_language: false
  enable_language_to_latent: false
  enable_language_to_action: false
  evaluate_reconstruction_narration: false
  action_prediction: false
  dyn_hidden: 768
  dyn_deter: 6144
  dyn_stoch: 48
  dyn_discrete: 32
  dyn_rec_depth: 1
  dyn_mean_act: "none"
  dyn_std_act: "sigmoid2"
  dyn_min_std: 0.1
  grad_heads: ["decoder", "reward", "cont"]
  language_grads: true
  units: 768
  act: "SiLU"
  norm: True
  encoder:
    {
      mlp_keys: "$^",
      cnn_keys: "image",
      act: "SiLU",
      norm: True,
      cnn_depth: 48,
      kernel_size: 4,
      minres: 4,
      mlp_layers: 3,
      mlp_units: 768,
      symlog_inputs: True,
    }
  decoder:
    {
      mlp_keys: "$^",
      cnn_keys: "image",
      act: "SiLU",
      norm: True,
      cnn_depth: 48,
      kernel_size: 4,
      minres: 4,
      mlp_layers: 3,
      mlp_units: 768,
      cnn_sigmoid: False,
      image_dist: mse,
      vector_dist: symlog_mse,
      outscale: 1.0,
    }
  actor:
    {
      layers: 3,
      dist: "normal",
      entropy: 3e-4,
      unimix_ratio: 0.01,
      std: "learned",
      min_std: 0.1,
      max_std: 1.0,
      temp: 0.1,
      lr: 4e-5,
      eps: 1e-5,
      grad_clip: 100.0,
      outscale: 0.01,
    }
  critic:
    {
      layers: 3,
      dist: "symlog_disc",
      slow_target: True,
      slow_target_update: 1,
      slow_target_fraction: 0.02,
      lr: 4e-5,
      eps: 1e-5,
      grad_clip: 100.0,
      outscale: 0.0,
    }
  reward_head:
    { layers: 1, dist: "symlog_disc", loss_scale: 1.0, outscale: 0.0 }
  action_prediction_head:
    { layers: 1, dist: "onehot", loss_scale: 1.0, outscale: 0.0 }
  cont_head: { layers: 1, loss_scale: 1.0, outscale: 1.0 }
  translator_head:
    {
      attention_heads: 2,
      encoder_blocks: 2,
      decoder_blocks: 2,
      dropout: 0.1,
      use_bottleneck: True,
      token_embed_size: 256,
      out_head_dim: 256,
      activation: "relu",
    }
  dyn_scale: 1.0
  rep_scale: 0.1
  kl_free: 1.0
  weight_decay: 0.0
  unimix_ratio: 0.01
  initial: "learned"

  # Training
  batch_size: 16
  batch_length: 64
  # The ratio of model update steps: environment steps
  train_ratio: 512
  pretrain: 0
  model_lr: 4e-5
  opt_eps: 1e-8
  grad_clip: 1000
  dataset_size: 100000
  opt: "adam"

  # Behavior.
  discount: 0.997
  discount_lambda: 0.95
  imag_horizon: 15
  imag_gradient: "dynamics"
  imag_gradient_mix: 0.0
  eval_state_mean: False

  # Exploration
  expl_behavior: "greedy"
  expl_until: 0
  expl_extr_scale: 0.0
  expl_intr_scale: 1.0
  disag_target: "stoch"
  disag_log: True
  disag_models: 10
  disag_offset: 1
  disag_layers: 4
  disag_units: 400
  disag_action_cond: False

dmc_proprio:
  steps: 5e5
  action_repeat: 2
  envs: 4
  train_ratio: 512
  video_pred_log: false
  encoder: { mlp_keys: ".*", cnn_keys: "$^" }
  decoder: { mlp_keys: ".*", cnn_keys: "$^" }

dmc_vision:
  steps: 1e6
  action_repeat: 2
  envs: 4
  train_ratio: 512
  video_pred_log: true
  encoder: { mlp_keys: "$^", cnn_keys: "image" }
  decoder: { mlp_keys: "$^", cnn_keys: "image" }

crafter:
  task: crafter_reward
  step: 1e6
  action_repeat: 1
  envs: 1
  eval_episode_num: 1
  eval_every: 500
  train_ratio: 512
  video_pred_log: true
  log_every: 500
  no_convert_list: ["semantic", "inventory", "achievements"]
  actor: { dist: "onehot", std: "none" }
  imag_gradient: "reinforce"

crafter-language:
  task: crafter_reward
  step: 1e6
  action_repeat: 1
  envs: 1
  eval_episode_num: 1
  eval_every: 500
  train_ratio: 512
  video_pred_log: true
  log_every: 500
  enable_language: true
  enc_max_length: 16
  dec_max_length: 150
  vocab_path: vocab/crafter.json
  narrator: { narration_key: ["semantic", "inventory", "achievements"] }
  no_convert_list: ["semantic", "inventory", "achievements"]
  actor: { dist: "onehot", std: "none" }
  imag_gradient: "reinforce"

crafter-language-small:
  task: crafter_reward
  step: 1e6
  action_repeat: 1
  envs: 1
  eval_episode_num: 1
  eval_every: 500
  train_ratio: 512
  video_pred_log: true
  log_every: 500
  enable_language: true
  enc_max_length: 16
  dec_max_length: 150
  vocab_path: vocab/crafter.json
  narrator: { narration_key: ["semantic", "inventory", "achievements"] }
  no_convert_list: ["semantic", "inventory", "achievements"]
  encoder: { cnn_keys: "image", cnn_depth: 64 }
  decoder: { cnn_keys: "image", cnn_depth: 64 }
  dyn_hidden: 512
  dyn_deter: 1024
  units: 512
  actor: { layers: 3, dist: "onehot", std: "none" }
  value: { layers: 3 }
  reward_head: { layers: 1 }
  cont_head: { layers: 1 }
  imag_gradient: "reinforce"

crafter-reconstruction:
  task: crafter_reward
  step: 1e6
  evaluate_reconstruction_narration: true
  action_repeat: 1
  envs: 1
  eval_episode_num: 1
  eval_every: 500
  train_ratio: 512
  video_pred_log: true
  log_every: 500
  no_convert_list: ["semantic", "inventory", "achievements"]
  encoder:
    { mlp_keys: "flattened_grid|flattened_inventory|flattened_achievements" }
  decoder:
    {
      mlp_keys: "flattened_grid|flattened_inventory|flattened_achievements",
      cnn_keys: "image",
    }
  actor: { dist: "onehot", std: "none" }
  imag_gradient: "reinforce"

crafter-reconstruction-small:
  task: crafter_reward
  step: 1e6
  evaluate_reconstruction_narration: true
  action_repeat: 1
  envs: 1
  eval_episode_num: 1
  eval_every: 500
  train_ratio: 512
  video_pred_log: true
  log_every: 500
  no_convert_list: ["semantic", "inventory", "achievements"]
  encoder:
    {
      mlp_keys: "flattened_grid|flattened_inventory|flattened_achievements",
      cnn_keys: "image",
      cnn_depth: 64,
      mlp_layers: 3,
      mlp_units: 1024,
    }
  decoder:
    {
      mlp_keys: "flattened_grid|flattened_inventory|flattened_achievements",
      cnn_keys: "image",
      cnn_depth: 64,
      mlp_layers: 3,
      mlp_units: 1024,
    }
  dyn_hidden: 512
  dyn_deter: 1024
  units: 512
  actor: { layers: 3, dist: "onehot", std: "none" }
  value: { layers: 3 }
  reward_head: { layers: 1 }
  cont_head: { layers: 1 }
  imag_gradient: "reinforce"

atari100k:
  steps: 4e5
  envs: 1
  action_repeat: 4
  train_ratio: 1024
  video_pred_log: true
  eval_episode_num: 100
  actor: { dist: "onehot", std: "none" }
  imag_gradient: "reinforce"
  stickey: False
  lives: unused
  noops: 30
  resize: opencv
  actions: needed
  time_limit: 108000

minecraft:
  task: minecraft_diamond
  step: 1e8
  parallel: True
  envs: 16
  # no eval
  eval_episode_num: 0
  eval_every: 1e4
  action_repeat: 1
  train_ratio: 16
  video_pred_log: true
  dyn_hidden: 1024
  dyn_deter: 4096
  units: 1024
  encoder:
    {
      mlp_keys: "inventory|inventory_max|equipped|health|hunger|breath|obs_reward",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  decoder:
    {
      mlp_keys: "inventory|inventory_max|equipped|health|hunger|breath",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  actor: { layers: 5, dist: "onehot", std: "none" }
  value: { layers: 5 }
  reward_head: { layers: 5 }
  cont_head: { layers: 5 }
  imag_gradient: "reinforce"
  break_speed: 100.0
  time_limit: 36000

memorymaze:
  steps: 1e8
  action_repeat: 2
  actor: { dist: "onehot", std: "none" }
  imag_gradient: "reinforce"
  task: "memorymaze_9x9"

minigrid:
  steps: 1e5
  envs: 1
  action_repeat: 1
  eval_episode_num: 1
  eval_n_consecutive_trajectories: 2
  eval_every: 1000
  log_every: 500
  actor: { dist: "onehot", std: "none" }
  imag_gradient: "reinforce"
  actions: needed
  video_pred_log: true
  task: "minigrid_teleport_complex"
  time_limit: 1024

minigrid-language:
  steps: 1e5
  envs: 1
  action_repeat: 1
  eval_episode_num: 1
  eval_n_consecutive_trajectories: 2
  eval_every: 1000
  log_every: 500
  narrator: { narration_key: ["occupancy_grid"] }
  actor: { dist: "onehot", std: "none" }
  imag_gradient: "reinforce"
  actions: needed
  enable_language: true
  vocab_path: vocab/minigrid_teleport_complex.json
  dec_max_length: 200
  enc_max_length: 16
  video_pred_log: true
  task: "minigrid_teleport_complex"
  time_limit: 1024

minigrid-reconstruction:
  steps: 1e5
  envs: 1
  action_repeat: 1
  eval_episode_num: 1
  eval_every: 1000
  log_every: 500
  encoder: { mlp_keys: "flattened_occupancy_grid" }
  decoder: { mlp_keys: "flattened_occupancy_grid" }
  actor: { dist: "onehot", std: "none" }
  imag_gradient: "reinforce"
  actions: needed
  evaluate_reconstruction_narration: true
  eval_n_consecutive_trajectories: 2
  video_pred_log: true
  task: "minigrid_teleport_complex"
  time_limit: 1024

minigrid-reconstruction-small:
  steps: 1e5
  envs: 1
  action_repeat: 1
  eval_episode_num: 1
  eval_every: 1000
  log_every: 500
  encoder:
    {
      mlp_keys: "flattened_occupancy_grid",
      cnn_keys: "image",
      cnn_depth: 64,
      mlp_layers: 3,
      mlp_units: 1024,
    }
  decoder:
    {
      mlp_keys: "flattened_occupancy_grid",
      cnn_keys: "image",
      cnn_depth: 64,
      mlp_layers: 3,
      mlp_units: 1024,
    }
  dyn_hidden: 512
  dyn_deter: 1024
  units: 512
  actor: { layers: 3, dist: "onehot", std: "none" }
  value: { layers: 3 }
  reward_head: { layers: 1 }
  cont_head: { layers: 1 }
  imag_gradient: "reinforce"
  actions: needed
  evaluate_reconstruction_narration: true
  eval_n_consecutive_trajectories: 2
  video_pred_log: true
  task: "minigrid_teleport_complex"
  time_limit: 1024

minedojo:
  steps: 1e8
  envs: 1
  eval_episode_num: 0
  eval_every: 1e4
  action_repeat: 1
  train_ratio: 16
  log_every: 1000
  resize: opencv
  actions: needed
  video_pred_log: true
  task: "minedojo_hunt_cow"
  minedojo_task_id: "hunt_cow"
  time_limit: 1000
  enable_language: true
  narrator: { narration_key: "image" }
  world_seed: 128
  vocab_path: vocab/mindojo_hunt_cow.json
  prompt_path: captions/minedojo.json
  mineclip_ckpt_path: attn.pth
  dec_max_length: 50
  enc_max_length: 16
  dyn_hidden: 1024
  dyn_deter: 4096
  units: 1024
  encoder:
    {
      mlp_keys: "compass|position|voxel_meta",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  decoder:
    {
      mlp_keys: "compass|position",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  actor: { layers: 5, dist: "onehot", std: "none" }
  value: { layers: 5 }
  reward_head: { layers: 5 }
  cont_head: { layers: 5 }
  imag_gradient: "reinforce"
  # checkpoint: "/data/Matt/dev/somniloquy-dreamer-v3/logdir/minedojo-hunt-cow/dreamer-agent-step-412500.pt"

panda_push:
  steps: 1e8
  action_repeat: 1
  envs: 16
  train_ratio: 64
  video_pred_log: true
  eval_episode_num: 0
  eval_every: 10000
  enable_language: true
  time_limit: 36000
  log_every: 1000
  dyn_hidden: 1024
  dyn_deter: 4096
  units: 1024
  task: "panda_push_colour"
  vocab_path: vocab/panda_push_colour.json
  narrator: { narration_key: "privileged_obs" }
  encoder:
    {
      mlp_keys: "$^",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  decoder:
    {
      mlp_keys: "$^",
      cnn_keys: "image",
      cnn_depth: 96,
      mlp_layers: 5,
      mlp_units: 1024,
    }
  dec_max_length: 100
  enc_max_length: 16
  actor: { layers: 5 }
  value: { layers: 5 }
  reward_head: { layers: 5 }
  cont_head: { layers: 5 }
  # checkpoint: "/home/mattbarker/dev/somniloquy-dreamer-v3/logdir/panda-push-colour-with-lang/dreamer-agent-step-102500.pt"

safegym:
  steps: 2e4
  envs: 1
  action_repeat: 1
  eval_episode_num: 1
  eval_every: 500
  dyn_hidden: 1024
  dyn_deter: 4096
  units: 1024
  log_every: 500
  encoder: { cnn_keys: "image", cnn_depth: 64, mlp_layers: 3, mlp_units: 1024 }
  decoder: { cnn_keys: "image", cnn_depth: 64, mlp_layers: 3, mlp_units: 1024 }
  actor: { layers: 3, dist: "onehot", std: "none" }
  value: { layers: 3 }
  reward_head: { layers: 3 }
  cont_head: { layers: 3 }
  narrator: { narration_key: ["occupancy_grid"] }
  imag_gradient: "reinforce"
  enable_language: true
  evaluate_reconstruction_narration: false
  vocab_path: vocab/safegym_island_navigation.json
  dec_max_length: 50
  enc_max_length: 16
  video_pred_log: true
  task: "safegym_island_navigation"
  time_limit: 1024
  conditional_actions: false
  # checkpoint: "/home/mattbarker/dev/somniloquy-dreamer-v3/logdir/safegym-seed-50/latest.pt"

ai2thor:
  steps: 1e8
  envs: 1
  action_repeat: 1
  eval_episode_num: 1
  eval_every: 10000
  dataset_size: 50000
  train_ratio: 64
  prefill: 2500
  actor: { dist: "onehot", std: "none" }
  imag_gradient: "reinforce"
  narrator:
    {
      narration_key:
        [
          "open",
          "close",
          "pickup",
          "put",
          "slice",
          "throw",
          "toggle_off",
          "toggle_on",
          "break",
          "drop",
          "agent_position",
        ],
    }
  no_convert_list:
    [
      "open",
      "close",
      "pickup",
      "put",
      "slice",
      "throw",
      "toggle_off",
      "toggle_on",
      "break",
      "drop",
      "agent_position",
    ]
  enable_language: True
  evaluate_reconstruction_narration: false
  vocab_path: vocab/ai2thor.json
  dec_max_length: 200
  enc_max_length: 16
  video_pred_log: true
  task: "ai2thor_pickup"
  time_limit: 1000
  conditional_actions: false
  n_eval_samples: 3
  eval_trajectory_length: 15
  eval_n_consecutive_trajectories: 60
  # checkpoint: "/home/mattbarker/dev/somniloquy-dreamer-v3/logdir/safegym-seed-50/latest.pt"

ai2thor-reconstruction:
  steps: 1e8
  envs: 1
  action_repeat: 1
  eval_episode_num: 1
  eval_every: 10000
  dataset_size: 50000
  train_ratio: 64
  prefill: 2500
  encoder:
    {
      mlp_keys: "agent_position|pickup_vec|drop_vec|open_vec|close_vec|toggle_on_vec|toggle_off_vec|break_vec|throw_vec|slice_vec|put_object_vec|put_receptacle_vec",
    }
  decoder:
    {
      mlp_keys: "agent_position|pickup_vec|drop_vec|open_vec|close_vec|toggle_on_vec|toggle_off_vec|break_vec|throw_vec|slice_vec|put_object_vec|put_receptacle_vec",
    }
  actor: { dist: "onehot", std: "none" }
  imag_gradient: "reinforce"
  narrator:
    {
      narration_key:
        [
          "open",
          "close",
          "pickup",
          "put",
          "slice",
          "throw",
          "toggle_off",
          "toggle_on",
          "break",
          "drop",
        ],
    }
  no_convert_list:
    [
      "open",
      "close",
      "pickup",
      "put",
      "slice",
      "throw",
      "toggle_off",
      "toggle_on",
      "break",
      "drop",
    ]
  enable_language: False
  evaluate_reconstruction_narration: True
  vocab_path: vocab/ai2thor.json
  dec_max_length: 200
  enc_max_length: 16
  video_pred_log: true
  task: "ai2thor_pickup"
  time_limit: 1000
  conditional_actions: false
  n_eval_samples: 3
  eval_trajectory_length: 15
  eval_n_consecutive_trajectories: 60

ai2thor-reconstruction-small:
  steps: 1e8
  envs: 1
  action_repeat: 1
  eval_episode_num: 1
  eval_every: 5000
  train_ratio: 64
  prefill: 2500
  encoder:
    {
      mlp_keys: "agent_position|pickup_vec|drop_vec|open_vec|close_vec|toggle_on_vec|toggle_off_vec|break_vec|throw_vec|slice_vec|put_object_vec|put_receptacle_vec",
      cnn_keys: "image",
      cnn_depth: 64,
      mlp_layers: 3,
      mlp_units: 512,
    }
  decoder:
    {
      mlp_keys: "agent_position|pickup_vec|drop_vec|open_vec|close_vec|toggle_on_vec|toggle_off_vec|break_vec|throw_vec|slice_vec|put_object_vec|put_receptacle_vec",
      cnn_keys: "image",
      cnn_depth: 64,
      mlp_layers: 3,
      mlp_units: 512,
    }
  dyn_hidden: 512
  dyn_deter: 1024
  units: 512
  actor: { layers: 3, dist: "onehot", std: "none" }
  value: { layers: 3 }
  reward_head: { layers: 1 }
  cont_head: { layers: 1 }
  imag_gradient: "reinforce"
  narrator:
    {
      narration_key:
        [
          "open",
          "close",
          "pickup",
          "put",
          "slice",
          "throw",
          "toggle_off",
          "toggle_on",
          "break",
          "drop",
        ],
    }
  no_convert_list:
    [
      "open",
      "close",
      "pickup",
      "put",
      "slice",
      "throw",
      "toggle_off",
      "toggle_on",
      "break",
      "drop",
    ]
  enable_language: False
  evaluate_reconstruction_narration: True
  vocab_path: vocab/ai2thor.json
  dec_max_length: 200
  enc_max_length: 16
  video_pred_log: true
  task: "ai2thor_pickup"
  time_limit: 1000
  conditional_actions: false
  n_eval_samples: 3
  eval_trajectory_length: 15
  eval_n_consecutive_trajectories: 1000

debug:
  debug: True
  pretrain: 1
  prefill: 1
  batch_size: 10
  batch_length: 20
